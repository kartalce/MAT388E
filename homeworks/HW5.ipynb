{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5\n",
    "\n",
    "For this homework, we are going to work with [*Indoor User Movement Prediction from RSS data*](https://archive.ics.uci.edu/ml/datasets/Indoor+User+Movement+Prediction+from+RSS+data) dataset from UCI.  The homework is due Friday, December 21st midnight. \n",
    "\n",
    "## Task 1\n",
    "\n",
    "Download the dataset and unzip it in under a subdirectory of `data` folder named `rss_data`.\n",
    "\n",
    "The files we are interested is in the subfolder `dataset`.  Each of these files whose names that start with `MovementAAL_RSS_` contain data collected from indivuduals. Each of these files represent a single data point.  There are 314 of these files, and hence, you have 314 data points.  Each file has 4 columns but the number of rows change from file to file.  \n",
    "\n",
    "There is also a file named `MovementALL_target.csv` in that folder. This file tells us the class each of these measurements are assigned. Some of these measurements are labelled with +1 and some are labelled with -1.\n",
    "\n",
    "## Task 2\n",
    "\n",
    "Construct a SVM model that separates +1 labelled data points from -1 data points.  You must first solve the problem that these datapoints do not have the same number of rows even though they all have the same number of columns. \n",
    "\n",
    "## Task 3\n",
    "\n",
    "Using [Keras](https://keras.io/getting-started/sequential-model-guide/) write a neural network model that separates +1 labelled data points from -1 data points.\n",
    "\n",
    "## Notes\n",
    "\n",
    "1. You must document each step of your tasks: what are you doing, why are you doing it, what problems you encountered and how you solved it.  All of these must be explained and documented.  Solutions without sufficient documentations will be penalized accordingly. 50% of your points will come from your code, while the other 50% will come from your explanations.\n",
    "\n",
    "1. You can use MS Excel to inspect the files, but loading them up to python using pandas and inspecting them there under jupyter is easier.\n",
    "\n",
    "3. Put the data in a separate subfolder of your `data` folder and rename it `rss_data`. I'll take points off if the data is not saved under the correct place.\n",
    "\n",
    "1. For both of Task 2 and Task 3, you must split your data into a train and test set, and then evaluate the accuracy of your model on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ceren\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check the size of each data point as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum size of the data is: 19\n",
      "maximum size of the data is: 129\n"
     ]
    }
   ],
   "source": [
    "length = []\n",
    "\n",
    "for i in range(314):\n",
    "    filename = os.path.expanduser('~/MAT388E/data/rss_data/dataset/MovementAAL_RSS_'+str(i+1)+'.csv')\n",
    "    df = read_csv(filename, header=0)\n",
    "    length.append(len(df))\n",
    "    del df\n",
    "print('minimum size of the data is:',min(length))\n",
    "print('maximum size of the data is:',max(length))\n",
    "del length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of each data point will be reduced to 19 rows since it is the min size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for i in range(314):\n",
    "    filename = os.path.expanduser('~/MAT388E/data/rss_data/dataset/MovementAAL_RSS_'+str(i+1)+'.csv')\n",
    "    df = read_csv(filename)\n",
    "    a = df.iloc[0:19,0].tolist()\n",
    "    b = df.iloc[0:19,1].tolist()\n",
    "    c = df.iloc[0:19,2].tolist()\n",
    "    d = df.iloc[0:19,3].tolist()\n",
    "    values=[a,b,c,d]\n",
    "    sequences.append(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading target data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = read_csv(os.path.expanduser('~/MAT388E/data/rss_data/dataset/MovementAAL_target.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reshape the data, we will first convert the data to numpy array. The data is reshaped by the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=np.array(sequences)\n",
    "reshaped = variables.reshape((314,4*19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    158\n",
       "-1    156\n",
       "Name:  class_label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.iloc[:,1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is splitted into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reshaped, target.iloc[:,1], test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM model will be built in the second task. The model is created and fit to data as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = y_train.apply(lambda x: 1 if x==1 else 0)\n",
    "y_test_binary = y_test.apply(lambda x: 1 if x==1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(kernel=\"rbf\",gamma=0.05,C=1)\n",
    "svm_clf.fit(X_train, y_train_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is evaluated as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion matrix of the test data:\n",
      " [[40  4]\n",
      " [18 33]]\n",
      "accuracy score of the test data:\n",
      " 0.7684210526315789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "predicted=svm_clf.predict(X_test)\n",
    "\n",
    "print('\\nconfusion matrix of the test data:\\n',confusion_matrix(predicted,y_test_binary))\n",
    "print('accuracy score of the test data:\\n',accuracy_score(predicted,y_test_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score in the test data is 76%. The confusion matrix is shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network model will be built in this task.\n",
    "I will first convert the target variable into binary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf = Sequential()\n",
    "\n",
    "nn_clf.add(Dense(15, activation='sigmoid', input_dim=76))\n",
    "nn_clf.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "nn_clf.compile(optimizer='RMSprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 219 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5495 - acc: 0.7580 - val_loss: 0.6489 - val_acc: 0.6737\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 0s 46us/step - loss: 0.5491 - acc: 0.7534 - val_loss: 0.6487 - val_acc: 0.6737\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 0s 64us/step - loss: 0.5492 - acc: 0.7626 - val_loss: 0.6483 - val_acc: 0.6737\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 0s 41us/step - loss: 0.5482 - acc: 0.7489 - val_loss: 0.6483 - val_acc: 0.6632\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 0s 50us/step - loss: 0.5481 - acc: 0.7580 - val_loss: 0.6481 - val_acc: 0.6632\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 0s 68us/step - loss: 0.5472 - acc: 0.7580 - val_loss: 0.6484 - val_acc: 0.6632\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 0s 73us/step - loss: 0.5482 - acc: 0.7489 - val_loss: 0.6489 - val_acc: 0.6737\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5466 - acc: 0.7580 - val_loss: 0.6487 - val_acc: 0.6737\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 0s 80us/step - loss: 0.5458 - acc: 0.7534 - val_loss: 0.6493 - val_acc: 0.6737\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 0s 50us/step - loss: 0.5453 - acc: 0.7580 - val_loss: 0.6491 - val_acc: 0.6737\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 0s 77us/step - loss: 0.5452 - acc: 0.7534 - val_loss: 0.6490 - val_acc: 0.6737\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 0s 46us/step - loss: 0.5444 - acc: 0.7534 - val_loss: 0.6483 - val_acc: 0.6737\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 0s 82us/step - loss: 0.5441 - acc: 0.7580 - val_loss: 0.6487 - val_acc: 0.6737\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 0s 41us/step - loss: 0.5433 - acc: 0.7580 - val_loss: 0.6480 - val_acc: 0.6737\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 0s 84us/step - loss: 0.5433 - acc: 0.7534 - val_loss: 0.6476 - val_acc: 0.6842\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 0s 46us/step - loss: 0.5424 - acc: 0.7580 - val_loss: 0.6477 - val_acc: 0.6842\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 0s 77us/step - loss: 0.5435 - acc: 0.7580 - val_loss: 0.6477 - val_acc: 0.6842\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 0s 64us/step - loss: 0.5416 - acc: 0.7580 - val_loss: 0.6474 - val_acc: 0.6842\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 0s 68us/step - loss: 0.5409 - acc: 0.7580 - val_loss: 0.6472 - val_acc: 0.6842\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5418 - acc: 0.7580 - val_loss: 0.6472 - val_acc: 0.6842\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 0s 82us/step - loss: 0.5402 - acc: 0.7626 - val_loss: 0.6473 - val_acc: 0.6842\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 0s 80us/step - loss: 0.5402 - acc: 0.7626 - val_loss: 0.6476 - val_acc: 0.6947\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 0s 50us/step - loss: 0.5394 - acc: 0.7534 - val_loss: 0.6480 - val_acc: 0.6947\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 0s 68us/step - loss: 0.5396 - acc: 0.7717 - val_loss: 0.6481 - val_acc: 0.6947\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5382 - acc: 0.7534 - val_loss: 0.6480 - val_acc: 0.6947\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 0s 46us/step - loss: 0.5378 - acc: 0.7717 - val_loss: 0.6480 - val_acc: 0.6947\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 0s 73us/step - loss: 0.5375 - acc: 0.7717 - val_loss: 0.6481 - val_acc: 0.6947\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 0s 50us/step - loss: 0.5370 - acc: 0.7671 - val_loss: 0.6484 - val_acc: 0.6947\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 0s 75us/step - loss: 0.5370 - acc: 0.7671 - val_loss: 0.6480 - val_acc: 0.6947\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5361 - acc: 0.7717 - val_loss: 0.6482 - val_acc: 0.6947\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 0s 77us/step - loss: 0.5354 - acc: 0.7717 - val_loss: 0.6483 - val_acc: 0.6947\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 0s 82us/step - loss: 0.5353 - acc: 0.7717 - val_loss: 0.6484 - val_acc: 0.6947\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 0s 50us/step - loss: 0.5352 - acc: 0.7626 - val_loss: 0.6486 - val_acc: 0.6947\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 0s 46us/step - loss: 0.5350 - acc: 0.7626 - val_loss: 0.6486 - val_acc: 0.6947\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 0s 68us/step - loss: 0.5342 - acc: 0.7671 - val_loss: 0.6487 - val_acc: 0.6947\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 0s 46us/step - loss: 0.5336 - acc: 0.7717 - val_loss: 0.6486 - val_acc: 0.6947\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 0s 41us/step - loss: 0.5325 - acc: 0.7717 - val_loss: 0.6485 - val_acc: 0.6947\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 0s 64us/step - loss: 0.5321 - acc: 0.7717 - val_loss: 0.6485 - val_acc: 0.6947\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 0s 50us/step - loss: 0.5330 - acc: 0.7671 - val_loss: 0.6491 - val_acc: 0.6947\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 0s 73us/step - loss: 0.5321 - acc: 0.7671 - val_loss: 0.6488 - val_acc: 0.6947\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 0s 59us/step - loss: 0.5311 - acc: 0.7717 - val_loss: 0.6489 - val_acc: 0.6947\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 0s 77us/step - loss: 0.5309 - acc: 0.7671 - val_loss: 0.6489 - val_acc: 0.6947\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 0s 68us/step - loss: 0.5309 - acc: 0.7717 - val_loss: 0.6489 - val_acc: 0.6947\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 0s 50us/step - loss: 0.5295 - acc: 0.7717 - val_loss: 0.6490 - val_acc: 0.6947\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 0s 41us/step - loss: 0.5294 - acc: 0.7763 - val_loss: 0.6489 - val_acc: 0.6947\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 0s 50us/step - loss: 0.5303 - acc: 0.7717 - val_loss: 0.6485 - val_acc: 0.6947\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 0s 59us/step - loss: 0.5284 - acc: 0.7808 - val_loss: 0.6487 - val_acc: 0.6947\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 0s 59us/step - loss: 0.5285 - acc: 0.7808 - val_loss: 0.6491 - val_acc: 0.6947\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 0s 45us/step - loss: 0.5276 - acc: 0.7717 - val_loss: 0.6497 - val_acc: 0.6947\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 0s 36us/step - loss: 0.5281 - acc: 0.7717 - val_loss: 0.6490 - val_acc: 0.6947\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 0s 41us/step - loss: 0.5264 - acc: 0.7717 - val_loss: 0.6491 - val_acc: 0.6947\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 0s 68us/step - loss: 0.5266 - acc: 0.7717 - val_loss: 0.6492 - val_acc: 0.6947\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 0s 46us/step - loss: 0.5257 - acc: 0.7763 - val_loss: 0.6491 - val_acc: 0.6947\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 0s 41us/step - loss: 0.5262 - acc: 0.7763 - val_loss: 0.6490 - val_acc: 0.6947\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 0s 73us/step - loss: 0.5253 - acc: 0.7671 - val_loss: 0.6488 - val_acc: 0.6947\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5247 - acc: 0.7717 - val_loss: 0.6487 - val_acc: 0.6947\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 0s 46us/step - loss: 0.5239 - acc: 0.7763 - val_loss: 0.6492 - val_acc: 0.6947\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 0s 87us/step - loss: 0.5244 - acc: 0.7808 - val_loss: 0.6499 - val_acc: 0.6947\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 0s 64us/step - loss: 0.5237 - acc: 0.7763 - val_loss: 0.6505 - val_acc: 0.6947\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 0s 41us/step - loss: 0.5225 - acc: 0.7763 - val_loss: 0.6500 - val_acc: 0.6947\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 50us/step - loss: 0.5231 - acc: 0.7717 - val_loss: 0.6503 - val_acc: 0.6947\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 0s 91us/step - loss: 0.5223 - acc: 0.7717 - val_loss: 0.6496 - val_acc: 0.6947\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5226 - acc: 0.7763 - val_loss: 0.6498 - val_acc: 0.6947\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 0s 59us/step - loss: 0.5217 - acc: 0.7808 - val_loss: 0.6495 - val_acc: 0.6947\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 0s 46us/step - loss: 0.5203 - acc: 0.7808 - val_loss: 0.6498 - val_acc: 0.6947\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 0s 41us/step - loss: 0.5201 - acc: 0.7808 - val_loss: 0.6494 - val_acc: 0.6947\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5206 - acc: 0.7717 - val_loss: 0.6499 - val_acc: 0.6947\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 0s 77us/step - loss: 0.5191 - acc: 0.7808 - val_loss: 0.6502 - val_acc: 0.6947\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.5061 - acc: 0.760 - 0s 59us/step - loss: 0.5196 - acc: 0.7763 - val_loss: 0.6498 - val_acc: 0.6947\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 0s 87us/step - loss: 0.5185 - acc: 0.7808 - val_loss: 0.6496 - val_acc: 0.6947\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 0s 96us/step - loss: 0.5185 - acc: 0.7808 - val_loss: 0.6495 - val_acc: 0.6947\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 0s 123us/step - loss: 0.5182 - acc: 0.7763 - val_loss: 0.6498 - val_acc: 0.6947\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 0s 73us/step - loss: 0.5172 - acc: 0.7763 - val_loss: 0.6498 - val_acc: 0.6947\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 0s 77us/step - loss: 0.5183 - acc: 0.7763 - val_loss: 0.6493 - val_acc: 0.6947\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 0s 91us/step - loss: 0.5170 - acc: 0.7808 - val_loss: 0.6498 - val_acc: 0.6947\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 0s 100us/step - loss: 0.5163 - acc: 0.7671 - val_loss: 0.6502 - val_acc: 0.6947\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 0s 64us/step - loss: 0.5158 - acc: 0.7717 - val_loss: 0.6501 - val_acc: 0.6947\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 0s 68us/step - loss: 0.5160 - acc: 0.7763 - val_loss: 0.6507 - val_acc: 0.7053\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 0s 77us/step - loss: 0.5151 - acc: 0.7854 - val_loss: 0.6507 - val_acc: 0.6947\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 0s 150us/step - loss: 0.5145 - acc: 0.7763 - val_loss: 0.6514 - val_acc: 0.6947\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 0s 68us/step - loss: 0.5146 - acc: 0.7763 - val_loss: 0.6513 - val_acc: 0.6947\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 0s 64us/step - loss: 0.5136 - acc: 0.7854 - val_loss: 0.6515 - val_acc: 0.6947\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5142 - acc: 0.7854 - val_loss: 0.6510 - val_acc: 0.7053\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 0s 118us/step - loss: 0.5132 - acc: 0.7854 - val_loss: 0.6504 - val_acc: 0.6947\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 0s 59us/step - loss: 0.5131 - acc: 0.7854 - val_loss: 0.6508 - val_acc: 0.6947\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 0s 77us/step - loss: 0.5131 - acc: 0.7717 - val_loss: 0.6504 - val_acc: 0.6947\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5118 - acc: 0.7854 - val_loss: 0.6504 - val_acc: 0.6947\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 0s 64us/step - loss: 0.5115 - acc: 0.7854 - val_loss: 0.6507 - val_acc: 0.6947\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 0s 59us/step - loss: 0.5107 - acc: 0.7808 - val_loss: 0.6510 - val_acc: 0.6947\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 0s 59us/step - loss: 0.5116 - acc: 0.7808 - val_loss: 0.6513 - val_acc: 0.6947\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 0s 41us/step - loss: 0.5099 - acc: 0.7808 - val_loss: 0.6511 - val_acc: 0.6947\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 0s 50us/step - loss: 0.5094 - acc: 0.7854 - val_loss: 0.6510 - val_acc: 0.6947\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 0s 77us/step - loss: 0.5090 - acc: 0.7854 - val_loss: 0.6514 - val_acc: 0.6842\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 0s 55us/step - loss: 0.5089 - acc: 0.7808 - val_loss: 0.6517 - val_acc: 0.6842\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 0s 41us/step - loss: 0.5085 - acc: 0.7717 - val_loss: 0.6518 - val_acc: 0.6947\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 0s 77us/step - loss: 0.5077 - acc: 0.7900 - val_loss: 0.6524 - val_acc: 0.6947\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 0s 36us/step - loss: 0.5074 - acc: 0.7854 - val_loss: 0.6525 - val_acc: 0.6842\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 0s 87us/step - loss: 0.5067 - acc: 0.7808 - val_loss: 0.6528 - val_acc: 0.6842\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 0s 46us/step - loss: 0.5064 - acc: 0.7808 - val_loss: 0.6530 - val_acc: 0.6842\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 0s 82us/step - loss: 0.5060 - acc: 0.7854 - val_loss: 0.6526 - val_acc: 0.6947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e9d25eeef0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_clf.fit(X_train, y_train_binary, epochs=100, batch_size=75, verbose=1, validation_data=(X_test, y_test_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the test set as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (nn_clf.predict(X_test) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix of the test data:\n",
      " [[33  4]\n",
      " [25 33]]\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix of the test data:\\n',confusion_matrix(y_pred,y_test_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of the test data:\n",
      " 0.6947368421052632\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score of the test data:\\n',accuracy_score(y_pred,y_test_binary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the test set in the neural network model is 69% for this example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
